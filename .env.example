#### Core runtime
NODE_ENV=development
LOG_LEVEL=info
WEB_BASE_URL=http://localhost:3000
COMMIT_SHA=dev
TELEMETRY_TRACE=on

#### Omni queue
OMNI_STREAM_MESSAGES=omni.messages
OMNI_STREAM_OUTBOX=omni.outbox
OMNI_GROUP=omni-core
OMNI_BLOCK_MS=5000
OMNI_DISPATCH_POLL_MS=250
OMNI_DLQ_STREAM=omni.dlq

#### WhatsApp MCP
MCP_WHATSAPP_URL=ws://localhost:8080
MCP_TOKEN=changeme

#### Secrets
# Generate a random secret: https://generate-secret.vercel.app/32 or `openssl rand -base64 32`
AUTH_SECRET=your-random-secret-here

#### Persistence
# PostgreSQL (local via Docker)
POSTGRES_URL=postgresql://user:password@localhost:5432/ai_ysh

# Redis (local via Docker)
REDIS_URL=redis://localhost:6379

# MinIO for blob storage (S3-compatible, local via Docker)
BLOB_READ_WRITE_TOKEN=minioadmin:minioadmin@localhost:9000/ai-ysh

#### AI Providers
# For AI, use Ollama (local models)
# Set to 'local' or your Ollama endpoint
AI_GATEWAY_API_KEY=local

# Original Vercel configurations (for deployment)
# AI Gateway API Key (required for non-Vercel deployments)
# For Vercel deployments, OIDC tokens are used automatically
# AI_GATEWAY_API_KEY=****

# Instructions to create a Vercel Blob Store here: https://vercel.com/docs/storage/vercel-blob
# BLOB_READ_WRITE_TOKEN=****

# Instructions to create a PostgreSQL database here: https://vercel.com/docs/storage/vercel-postgres/quickstart
# POSTGRES_URL=****

# Instructions to create a Redis store here:
# https://vercel.com/docs/redis
# REDIS_URL=****

# Google Maps API key for geocoding and map views
NEXT_PUBLIC_GOOGLE_MAPS_API_KEY=your-google-maps-key

# AI Provider API Keys
# xAI/Grok API Key
XAI_API_KEY=your-xai-api-key-here

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# OpenAI API Key (for GPT models)
OPENAI_API_KEY=your-openai-api-key-here

# Google Vertex AI Configuration
GOOGLE_CLOUD_PROJECT_ID=your-gcp-project-id
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account-key.json

# Ollama Configuration (local AI models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=qwen3:30b

# Load Balancer Configuration
# Weights for the load balancing algorithm (must sum to 100)
LOAD_BALANCER_COST_WEIGHT=30
LOAD_BALANCER_LATENCY_WEIGHT=40
LOAD_BALANCER_RELIABILITY_WEIGHT=30

# Performance monitoring settings
PERFORMANCE_MONITORING_ENABLED=true
PERFORMANCE_METRICS_RETENTION_HOURS=168
PERFORMANCE_ALERT_THRESHOLD_LATENCY=5000
PERFORMANCE_ALERT_THRESHOLD_ERROR_RATE=0.05

# Provider priority and limits
PROVIDER_PRIORITY_ORDER=xai,ollama,anthropic,openai,google
MAX_COST_PER_REQUEST=0.10
MAX_LATENCY_MS=10000
PROVIDER_TIMEOUT_MS=30000
