# Sistema de Load Balancing e Monitoramento de IA

Este documento descreve o sistema completo implementado para altern√¢ncia inteligente de providers de IA, monitoramento de performance e load balancing baseado em custo e lat√™ncia.

## üöÄ Funcionalidades Implementadas

### 1. Teste de Providers

- ‚úÖ Altern√¢ncia entre local (Ollama), Vertex AI e gateway padr√£o
- ‚úÖ Scripts de teste automatizados
- ‚úÖ Verifica√ß√£o de conectividade e funcionalidade

### 2. Configura√ß√£o Ollama

- ‚úÖ Download autom√°tico de modelos necess√°rios
- ‚úÖ Modelos instalados: qwen3:30b, falcon3:latest, llama3.2-vision:latest, mistral:latest
- ‚úÖ Scripts de verifica√ß√£o de sa√∫de dos modelos

### 3. Monitoramento de Performance

- ‚úÖ Sistema de m√©tricas em tempo real
- ‚úÖ Rastreamento de lat√™ncia, custo e taxa de sucesso
- ‚úÖ API REST para consulta de m√©tricas
- ‚úÖ Integra√ß√£o com GCP Cloud Logging

### 4. Load Balancing Inteligente

- ‚úÖ Sele√ß√£o autom√°tica do melhor provider baseada em:
  - Custo por token
  - Lat√™ncia m√©dia
  - Taxa de sucesso
  - Carga atual
  - Prefer√™ncias do usu√°rio
- ‚úÖ API para tomada de decis√µes de roteamento
- ‚úÖ Gerenciamento de carga concorrente

## üìä Como Usar

### Testar Providers

```bash
# Executar testes de altern√¢ncia
node scripts/test-providers.js

# Testar configura√ß√£o Ollama
node scripts/test-ollama.js

# Testar sistema completo de load balancing
node scripts/test-load-balancing.js
```

### Configurar Ambiente

```bash
# Para usar provider local (Ollama)
AI_GATEWAY_API_KEY=local pnpm run dev

# Para usar Vertex AI
AI_GATEWAY_API_KEY=vertex pnpm run dev

# Para usar gateway padr√£o
AI_GATEWAY_API_KEY=your-key pnpm run dev
```

### APIs Dispon√≠veis

#### Sele√ß√£o de Provider Inteligente

```http
GET /api/load-balancing?modelType=chat&preferredProvider=xai&maxLatency=2000
```

Par√¢metros:

- `modelType`: `chat` | `vision` | `reasoning` | `artifact`
- `preferredProvider`: Provider preferido (opcional)
- `maxCost`: Custo m√°ximo por token (opcional)
- `maxLatency`: Lat√™ncia m√°xima em ms (opcional)

#### M√©tricas de Performance

```http
GET /api/monitoring/performance?hours=24
```

Retorna estat√≠sticas de todos os providers nas √∫ltimas N horas.

#### Gerenciamento de Carga

```http
POST /api/load-balancing
Content-Type: application/json

{
  "provider": "xai",
  "action": "increment" | "decrement"
}
```

## üèóÔ∏è Arquitetura

### Componentes Principais

1. **Performance Monitor** (`lib/monitoring/performance.ts`)
   - Coleta m√©tricas de lat√™ncia, custo e sucesso
   - Armazenamento em mem√≥ria com limite de 1000 entradas
   - C√°lculo de custos baseado em provider/modelo

2. **Load Balancer** (`lib/load-balancing/load-balancer.ts`)
   - Algoritmo de pontua√ß√£o multi-fator
   - Gerenciamento de carga concorrente
   - Configura√ß√µes personaliz√°veis por provider

3. **Provider Integration** (`lib/ai/providers.ts`)
   - Fun√ß√£o `getSmartProvider()` para sele√ß√£o inteligente
   - Integra√ß√£o com sistema de load balancing
   - Fallback autom√°tico em caso de falhas

### Algoritmo de Load Balancing

O sistema usa uma pontua√ß√£o ponderada baseada em:

- **Custo** (30%): Menor custo = maior pontua√ß√£o
- **Lat√™ncia** (40%): Menor lat√™ncia = maior pontua√ß√£o
- **Confiabilidade** (30%): Maior taxa de sucesso = maior pontua√ß√£o
- **Carga** (10%): Menor carga atual = maior pontua√ß√£o
- **Prioridade** (10%): Configura√ß√£o manual de prioridade

## üìà Monitoramento

### M√©tricas Coletadas

Por provider:

- Total de requisi√ß√µes
- Taxa de sucesso
- Lat√™ncia m√©dia
- Custo total
- Tokens m√©dios por requisi√ß√£o

Por modelo:

- Lat√™ncia m√©dia
- Taxa de sucesso
- Custo por token

### Visualiza√ß√£o

As m√©tricas podem ser visualizadas via:

- API REST: `/api/monitoring/performance`
- Logs do console com prefixo `[PERFORMANCE]`
- GCP Cloud Logging (configur√°vel)

## üîß Configura√ß√£o

### Providers Suportados

| Provider | Modelo Base | Custo/1K tokens | Status |
|----------|-------------|----------------|---------|
| xAI | Grok | $0.0015 | ‚úÖ Ativo |
| Anthropic | Claude 3.5 | $0.0030 | ‚úÖ Ativo |
| OpenAI | GPT-4o | $0.0025 | ‚úÖ Ativo |
| Google | Gemini Pro | $0.0010 | ‚úÖ Ativo |
| Ollama | V√°rios | $0.0000 | ‚úÖ Local |

### Configura√ß√£o Personalizada

```typescript
import { loadBalancer } from '@/lib/load-balancing/load-balancer';

// Configurar pesos para um provider espec√≠fico
loadBalancer.configureProvider('xai', {
  costWeight: 0.5,      // Dar mais peso ao custo
  latencyWeight: 0.3,   // Menos peso √† lat√™ncia
  maxConcurrent: 15     // Aumentar limite concorrente
});
```

## üß™ Testes

### Testes Automatizados

```bash
# Testar altern√¢ncia de providers
npm run test:providers

# Testar m√©tricas de performance
npm run test:metrics

# Testar load balancing
npm run test:load-balancing
```

### Testes Manuais

1. **Verificar funcionamento b√°sico**:

   ```bash
   curl "http://localhost:3000/api/load-balancing?modelType=chat"
   ```

2. **Testar com restri√ß√µes**:

   ```bash
   curl "http://localhost:3000/api/load-balancing?modelType=vision&maxLatency=1000&preferredProvider=ollama"
   ```

3. **Verificar m√©tricas**:

   ```bash
   curl "http://localhost:3000/api/monitoring/performance?hours=1"
   ```

## üö® Troubleshooting

### Problemas Comuns

1. **Modelo Ollama n√£o responde**
   - Verificar se o servi√ßo est√° rodando: `ollama list`
   - Reiniciar servi√ßo: `ollama serve`
   - Verificar modelos instalados

2. **Load balancer sempre escolhe o mesmo provider**
   - Verificar m√©tricas: as decis√µes s√£o baseadas em dados reais
   - Ajustar pesos de configura√ß√£o se necess√°rio

3. **Altas lat√™ncias**
   - Verificar conectividade com providers externos
   - Considerar usar provider local (Ollama) como fallback

### Logs √öteis

```bash
# Ver logs de performance
grep "\[PERFORMANCE\]" logs/app.log

# Ver decis√µes de load balancing
grep "Load balancing decision" logs/app.log
```

## üîÆ Melhorias Futuras

- [ ] Dashboard web para visualiza√ß√£o de m√©tricas
- [ ] Alertas autom√°ticos para degrada√ß√£o de performance
- [ ] Cache inteligente de respostas
- [ ] Auto-scaling baseado na demanda
- [ ] Integra√ß√£o com Prometheus/Grafana
- [ ] Machine learning para predi√ß√£o de carga

## üìù Notas de Desenvolvimento

- O sistema usa imports din√¢micos para evitar depend√™ncias circulares
- Todas as m√©tricas s√£o armazenadas em mem√≥ria (reiniciadas com o servidor)
- O load balancer funciona de forma stateless para cada requisi√ß√£o
- Fallback autom√°tico garante que o sistema sempre funcione, mesmo com falhas parciais
